# Dave Service - Complete Development Handoff

**Date:** 2026-01-10 (Updated)
**Status:** 83% coverage, 465 tests passing - Ready for Phase 1 completion
**Next Agent:** Add 4 test files to reach 85%+ coverage (see Phase 1 below)

---

## Quick Start for Next Agent

**To continue this work:**

1. **Read this entire document** - Contains accurate current status
2. **Review the plan**: `C:\Users\damiy\.claude\plans\logical-marinating-flask.md` (Full ProjectPhoenix compliance)
3. **Check current status**: 83% coverage (verified 2026-01-10), 465 tests passing, 0 failures
4. **Read the spec**: `ProjectPhoenix/docs/services/dave/spec.md`
5. **Available skills**: `testing-engineer`, `backend-developer`, `security-engineer`, `monitoring-observability-engineer`

**Immediate next task:** Create 4 test files to reach 85%+ coverage (Phase 1 critical path)

---

## Executive Summary

### What Dave Is
Dave is Employa's AI-powered career coach - a FastAPI service providing:
- **Conversational AI chat** (streaming and non-streaming) via Gemini
- **Knowledge base search** (hybrid semantic + fulltext) for career resources
- **Guardrails protection** (rate limiting, prompt injection, topic classification)
- **Admin prompt management** with version control
- **Nudge generation** for n8n workflow automation

### Current State (Updated 2026-01-10)

**Functional Implementation: ~95% Complete**
- âœ… All chat endpoints working (streaming + non-streaming)
- âœ… Knowledge base integration (hybrid search, articles, FAQs)
- âœ… Guardrails system (rate limiting, prompt injection, topic classification)
- âœ… Admin prompts with version control
- âœ… Nudge generation
- âœ… Authentication (API key + JWT)
- âœ… Conversation management and persistence
- âœ… Dual-write pattern for database migration (7/7 integration tests passing)

**Production Readiness: ~60% Complete (ProjectPhoenix compliance)**
- ğŸŸ¡ Testing: **83% coverage, 465 tests passing** (NEED 85%+ - 2% gap remaining)
- ğŸŸ¡ Documentation: Spec complete, runbook partial, ADRs needed
- ğŸŸ¡ Compliance: RLS âœ… (15 policies), mTLS âŒ, GCP Secret Manager âŒ, HIPAA audit logging âŒ
- ğŸŸ¡ Observability: Health checks âœ…, SLO metrics âŒ, OpenTelemetry âŒ, Dashboards âŒ
- ğŸŸ¢ Code Quality: Good structure, minor cleanup needed

### Governance Gates Status

From plan: `C:\Users\damiy\.claude\plans\logical-marinating-flask.md`

| Gate | Current | Target | Gap | Status |
|------|---------|--------|-----|--------|
| **1. Code Quality** | **83% coverage** | 85%+ | 2% | ğŸŸ¡ NEAR COMPLETE |
| **2. Documentation** | Partial | Complete | Medium | ğŸŸ¡ TODO |
| **3. Compliance** | RLS only | Full HIPAA | Large | ğŸŸ¡ TODO |
| **4. Observability** | Basic | Full stack | Large | ğŸŸ¡ TODO |
| **5. Cleanup** | Good | Excellent | Small | ğŸŸ¢ MOSTLY DONE |

---

## Development Journey (What's Been Done)

### Phase 1: Testing Infrastructure (IN PROGRESS - 83% complete)

**Goal:** 85%+ test coverage with REAL, meaningful tests

**Progress:**
- Started: 34% coverage, 23 tests (earlier session)
- Previous claim: 59% coverage, 257 tests (OUTDATED - from stale documentation)
- **ACTUAL Current (2026-01-10):** **83% coverage, 465 tests passing, 0 failures**
- Gap: 2% to reach 85% mandatory threshold

**Critical Modules Below 85% (Need Testing to Reach 85%+):**

| Module | Current Coverage | Gap | Priority | Estimated Effort |
|--------|------------------|-----|----------|------------------|
| **app/api/v1/endpoints/chat.py** | 68% | 17% | ğŸ”´ CRITICAL | 4-6 hours |
| **app/main.py** | 42% | 43% | ğŸ”´ CRITICAL | 6-8 hours |
| **app/api/v1/endpoints/prompts.py** | 29% | 56% | ğŸŸ  HIGH | 8-10 hours |
| **app/guardrails/rate_limiter.py** | 54% | 31% | ğŸŸ  HIGH | 5-7 hours |

**What's Missing:**
- **chat.py:** Streaming endpoint (`/stream` SSE logic), error handling, blocked message responses
- **main.py:** Readiness checks (Supabase/Gemini/database dependencies), graceful shutdown, Prometheus metrics initialization, lifespan hooks
- **prompts.py:** All admin endpoints (list, update, rollback, cache clearing, version management)
- **rate_limiter.py:** Redis operations (distributed mode, fallback on connection failure, stale entry cleanup)

**Total Estimated Effort to Reach 85%+:** 23-31 hours (3-4 days)

**Test Files Created (20+ total - comprehensive suite):**

1. âœ… **test_auth_working.py** - 14 tests, 89% coverage
   - API key authentication (valid/invalid/missing)
   - JWT token validation
   - Admin vs regular API key differentiation
   - Conversation ownership enforcement

2. âœ… **test_guardrails_rate_limiter.py** - 34 tests, 97% coverage (32 passing)
   - Tiered rate limiting (free: 5/min, basic: 15/min, premium: 30/min, admin: 100/min)
   - Token counting
   - Redis vs in-memory fallback
   - Usage tracking
   - Known issue: 2 tests failing due to timing issues in cleanup

3. âœ… **test_guardrails_prompt_injection.py** - 42 tests, 100% coverage
   - Jailbreak pattern detection
   - System override attempts (DAN, STAN, Omega)
   - Special character ratio thresholds
   - Redirect message generation

4. âœ… **test_guardrails_topic_classifier.py** - 38 tests, 100% coverage
   - Career keyword detection
   - Medical/therapy/legal/coding redirects
   - Greeting handling
   - Edge cases and mixed content

5. âœ… **test_guardrails_orchestrator.py** - 18 tests, 90% coverage (16 passing)
   - Check ordering (rate limit â†’ injection â†’ topic)
   - Short-circuit behavior
   - Parameter passing
   - Singleton pattern
   - Known issue: 2 tests running real guardrails instead of mocks

6. âœ… **test_repositories_conversation.py** - 33 tests, 90% coverage
   - Conversation CRUD operations
   - Message persistence
   - Conversation history retrieval
   - User-specific filtering

7. âœ… **test_repositories_knowledge.py** - 43 tests, 90% coverage
   - Cosine similarity calculations
   - Storage article loading and caching
   - HTML parsing with BeautifulSoup
   - Fulltext search (articles + FAQs)
   - Semantic search with embeddings
   - Hybrid search (65% semantic + 35% fulltext)

8. âœ… **test_repositories_prompts.py** - 22 tests, 81% coverage (21 passing)
   - Prompt retrieval by category/name
   - Version creation with auto-increment
   - Rollback functionality
   - Category enumeration
   - Known issue: 1 test with mock assertion issue

9. âœ… **test_services_prompt_manager.py** - 27 tests, 100% coverage
   - Prompt caching with TTL expiry
   - System prompt building
   - Welcome message generation
   - Cache clearing (global/category/prompt)
   - Fallback behavior

**Modules with 80%+ Coverage (11 total):**
- prompt_injection.py: 100%
- topic_classifier.py: 100%
- prompt_manager.py: 100%
- rate_limiter.py: 97%
- config.py: 96%
- logging.py: 94%
- guardrails/__init__.py: 90%
- conversation.py: 90%
- knowledge.py: 90%
- auth.py: 89%
- prompts.py: 81%

**Critical Work Remaining:**

1. **test_services_dave_chat.py** (PRIORITY 1)
   - File: `api/app/services/dave_chat.py` (145 statements @ 18%)
   - Impact: +8% coverage if brought to 85%
   - What to test:
     - `generate_response()` - Non-streaming chat
     - `stream_response()` - SSE streaming
     - Guardrails integration
     - Conversation creation/retrieval
     - Knowledge base search integration
     - Message persistence
     - Follow-up suggestions
     - Error handling

2. **test_routes_chat.py** (PRIORITY 2)
   - File: `api/app/routes/chat.py` (108 statements @ 23%)
   - Impact: +5% coverage
   - What to test:
     - POST `/chat/message` endpoint
     - GET `/chat/stream` endpoint
     - POST `/chat/start` endpoint
     - GET `/chat/conversations` endpoint
     - GET `/chat/conversations/{id}` endpoint
     - DELETE `/chat/conversations/{id}` endpoint
     - Authentication/authorization
     - Conversation ownership

3. **test_clients_gemini.py** (PRIORITY 3)
   - File: `api/app/clients/gemini.py` (127 statements @ 28%)
   - Impact: +5% coverage
   - What to test:
     - Circuit breaker (Closed â†’ Open â†’ Half-Open)
     - Non-streaming generation
     - Streaming generation
     - Embedding generation
     - Retry logic with exponential backoff
     - Health status tracking

**Testing Patterns Established:**

```python
# Standard test structure
import pytest
from unittest.mock import MagicMock, AsyncMock, patch

class TestServiceName:
    """Test service functionality."""

    @pytest.fixture
    def mock_dependency(self):
        """Create mock dependency."""
        mock = MagicMock()
        mock.method = AsyncMock(return_value=expected_value)
        return mock

    @pytest.fixture
    def service(self, mock_dependency):
        """Create service with mocked dependencies."""
        with patch('module.path.get_dependency', return_value=mock_dependency):
            return ServiceClass()

    @pytest.mark.unit
    @pytest.mark.asyncio
    async def test_method_success(self, service, mock_dependency):
        """Test method with successful scenario."""
        result = await service.method(param)

        assert result == expected
        mock_dependency.method.assert_called_once_with(param)
```

**Commands to Continue Testing:**

```bash
# Run full test suite
cd ProjectPhoenix/services/dave
python -m pytest tests/ --cov=api.app --cov-report=term-missing --cov-report=html -v

# Check if 85% threshold met
python -m pytest --cov=api.app --cov-report=term-missing --cov-fail-under=85

# Run specific test file
python -m pytest tests/test_services_dave_chat.py -v
```

### Phase 2-7: Not Started (See Plan)

**Phase 2: Security Hardening**
- Migrate secrets to GCP Secret Manager
- Implement mTLS for service-to-service
- Create Supabase RLS policies
- Security scanning (SAST/SCA/container)
- HIPAA compliance checklist

**Phase 3: Observability Enhancement**
- Prometheus metrics endpoint
- OpenTelemetry tracing
- Structured logging with PHI redaction
- SLO definition and alerting
- Cloud Monitoring dashboards

**Phase 4: Documentation Completion**
- Expand runbook with operational procedures
- Create ADRs for key decisions
- Complete OpenAPI spec
- Update standards checklist

**Phase 5: Code Cleanup & Optimization**
- Resolve all TODOs/FIXMEs
- Add missing type hints
- Performance optimization
- Dependency audit

**Phase 6: Load Testing**
- k6 load test scenarios
- Performance baseline establishment
- Cloud Run autoscaling tuning

**Phase 7: Final Validation**
- All governance gates verification
- End-to-end testing
- Production deployment

---

## Technical Architecture

### Service Structure

```
ProjectPhoenix/services/dave/
â”œâ”€â”€ api/
â”‚   â””â”€â”€ app/
â”‚       â”œâ”€â”€ main.py                    # FastAPI app entry point
â”‚       â”œâ”€â”€ config.py                  # Settings (Pydantic v2)
â”‚       â”œâ”€â”€ logging.py                 # Structured logging setup
â”‚       â”œâ”€â”€ routes/
â”‚       â”‚   â”œâ”€â”€ chat.py               # Chat endpoints (SSE + REST)
â”‚       â”‚   â”œâ”€â”€ knowledge.py          # Knowledge search/articles/FAQs
â”‚       â”‚   â”œâ”€â”€ admin_prompts.py      # Admin prompt management
â”‚       â”‚   â”œâ”€â”€ nudges.py             # Nudge generation
â”‚       â”‚   â””â”€â”€ health.py             # Health/readiness endpoints
â”‚       â”œâ”€â”€ services/
â”‚       â”‚   â”œâ”€â”€ dave_chat.py          # Core chat orchestration âš ï¸ NEEDS TESTS
â”‚       â”‚   â”œâ”€â”€ prompt_manager.py     # Prompt caching/loading âœ… 100%
â”‚       â”‚   â””â”€â”€ nudge_service.py      # Nudge generation logic
â”‚       â”œâ”€â”€ repositories/
â”‚       â”‚   â”œâ”€â”€ conversation.py       # Conversation persistence âœ… 90%
â”‚       â”‚   â”œâ”€â”€ knowledge.py          # Knowledge search âœ… 90%
â”‚       â”‚   â””â”€â”€ prompts.py            # Prompt version control âœ… 81%
â”‚       â”œâ”€â”€ clients/
â”‚       â”‚   â”œâ”€â”€ gemini.py             # Gemini AI client (circuit breaker) âš ï¸ NEEDS TESTS
â”‚       â”‚   â”œâ”€â”€ supabase.py           # Supabase client singleton
â”‚       â”‚   â””â”€â”€ http_client.py        # Shared HTTP client
â”‚       â”œâ”€â”€ guardrails/
â”‚       â”‚   â”œâ”€â”€ __init__.py           # Orchestrator âœ… 90%
â”‚       â”‚   â”œâ”€â”€ rate_limiter.py       # Tiered rate limiting âœ… 97%
â”‚       â”‚   â”œâ”€â”€ prompt_injection.py   # Injection detection âœ… 100%
â”‚       â”‚   â””â”€â”€ topic_classifier.py   # Topic classification âœ… 100%
â”‚       â”œâ”€â”€ middleware/
â”‚       â”‚   â””â”€â”€ auth.py               # API key + JWT auth âœ… 89%
â”‚       â””â”€â”€ schemas/
â”‚           â”œâ”€â”€ chat.py               # Chat request/response models
â”‚           â”œâ”€â”€ knowledge.py          # Search models
â”‚           â””â”€â”€ prompts.py            # Admin prompt models
â”œâ”€â”€ tests/                             # 9 test files, 272 tests
â”œâ”€â”€ Dockerfile                         # Multi-stage Docker build
â”œâ”€â”€ requirements.txt                   # Python dependencies
â””â”€â”€ docs/
    â”œâ”€â”€ spec.md                        # Complete service specification
    â”œâ”€â”€ runbook.md                     # Operational procedures (partial)
    â””â”€â”€ adr/                           # Architecture Decision Records
```

### Key Technical Decisions

**From `docs/adr/0001-dave-stack.md`:**

1. **FastAPI** over Flask/Django
   - Async support for streaming
   - Automatic OpenAPI generation
   - Type hints with Pydantic

2. **Gemini 1.5 Flash** (will migrate to Vertex AI)
   - Cost-effective for high volume
   - 1M token context window
   - Streaming support

3. **Supabase** for persistence
   - PostgreSQL with built-in auth
   - Storage for knowledge articles
   - RLS for multi-tenancy

4. **Circuit Breaker Pattern** for Gemini
   - 3 failures â†’ 60s cooldown
   - Prevents cascade failures
   - Health status tracking

5. **Hybrid Search** (65% semantic + 35% fulltext)
   - Semantic: Gemini embeddings
   - Fulltext: PostgreSQL ts_rank
   - Weighted blend for best results

6. **Tiered Rate Limiting**
   - Free: 5/min, 1000/day
   - Basic: 15/min, 3000/day
   - Premium: 30/min, 10000/day
   - Admin: 100/min, unlimited/day
   - Redis primary, in-memory fallback

### Dependencies

**Core:**
- fastapi==0.104.1
- uvicorn[standard]==0.24.0
- pydantic==2.5.0
- pydantic-settings==2.1.0

**AI/ML:**
- google-generativeai==0.3.1 (will migrate to google-cloud-aiplatform)

**Database:**
- supabase==2.0.3
- asyncpg==0.29.0

**Observability:**
- opentelemetry-api==1.21.0
- opentelemetry-sdk==1.21.0
- opentelemetry-instrumentation-fastapi==0.42b0
- prometheus-fastapi-instrumentator==6.1.0

**Testing:**
- pytest==7.4.3
- pytest-asyncio==0.21.1
- pytest-cov==4.1.0
- pytest-mock==3.12.0

**Other:**
- httpx==0.25.2
- beautifulsoup4==4.12.2
- redis==5.0.1

---

## Known Issues & Quirks

### Import Path Change
All imports changed from `from app.` to `from api.app.` across 17 files.

**Why:** Module structure is `api.app.*`, not `app.*`

**Fixed with:**
```bash
sed -i 's/from app\./from api.app./g' <files>
```

### Failing Tests (5 total, all low impact)

1. **test_check_blocks_after_day_limit** (rate_limiter)
   - Issue: `_clean_old_requests()` mutates state during time checks
   - Impact: Minor, module at 97%

2. **test_get_usage_memory** (rate_limiter)
   - Issue: Same cleanup timing issue
   - Impact: Minor

3. **test_get_prompt_by_category_name_filters_archived** (prompts)
   - Issue: Mock assertion needs fixing
   - Impact: Minor, module at 81%

4-5. **test_check_detects_prompt_injection**, **test_check_detects_jailbreak_attempt** (orchestrator)
   - Issue: Running real guardrails instead of mocks
   - Impact: Minor, module at 90%

### Configuration Fields Added

Added to `api/app/config.py`:
```python
cache_ttl_prompts: int = Field(300, env="CACHE_TTL_PROMPTS")
dave_api_key: Optional[str] = Field(None, env="DAVE_API_KEY")
admin_api_key: Optional[str] = Field(None, env="ADMIN_API_KEY")
rate_limit_enabled: bool = Field(True, env="RATE_LIMIT_ENABLED")
```

### Pydantic v2 Migration
Service uses Pydantic v2:
- `BaseSettings` â†’ `from pydantic_settings import BaseSettings`
- `.dict()` â†’ `.model_dump()`
- `@validator` â†’ `@field_validator`

---

## Key Implementation Details

### Guardrails Flow
```
User Message
    â†“
1. Rate Limiter (fastest check)
    â†“ (if blocked) â†’ 429 response
2. Prompt Injection Detector (security critical)
    â†“ (if blocked) â†’ redirect message
3. Topic Classifier (may use AI)
    â†“ (if blocked) â†’ redirect message
4. Allowed â†’ Continue to Gemini
```

### Chat Flow (Non-Streaming)
```
1. Run guardrails (rate limit â†’ injection â†’ topic)
2. Get or create conversation
3. Save user message to DB
4. Get conversation history (last 10 messages)
5. Search knowledge base (if include_resources=true)
6. Build system prompt (Dave personality + knowledge context)
7. Format history for Gemini
8. Call Gemini (generate)
9. Generate follow-up suggestions (rule-based)
10. Save assistant message to DB
11. Record request for rate limiting
12. Return response + resources + suggestions
```

### Chat Flow (Streaming)
```
1-7. Same as non-streaming
8. Stream from Gemini:
   - Yield resource event (knowledge base results)
   - Yield token events (as they arrive)
   - Yield suggestion event (follow-ups)
   - Yield done event (conversation_id + full_response)
   - OR yield error event (if exception)
9. Save assistant message to DB
10. Record request for rate limiting
```

### Knowledge Search Flow
```
Hybrid Search (default):
1. Fulltext search articles (PostgreSQL ts_rank)
2. Fulltext search FAQs
3. Semantic search articles (cosine similarity with Gemini embeddings)
4. Combine results with weighted scoring:
   - Fulltext score * 0.35
   - Semantic score * 0.65
5. Sort by combined score (descending)
6. Return top N results
```

### Prompt Version Control
```
Admin Updates Prompt:
1. Create new version (auto-increment version_number)
2. Insert into admin_prompt_versions table
3. Update current_version_id on admin_prompts table
4. Clear PromptManagerService cache (TTL or manual)

Rollback:
1. Verify version exists and belongs to prompt
2. Update current_version_id to target version
3. Cache automatically refreshes on next request
```

### Circuit Breaker (Gemini Client)
```
States:
- Closed: Normal operation
- Open: Reject all requests (after 3 failures)
- Half-Open: Allow 1 test request (after 60s cooldown)

Transitions:
- Closed â†’ Open: 3 consecutive failures
- Open â†’ Half-Open: After 60s timeout
- Half-Open â†’ Closed: Success
- Half-Open â†’ Open: Failure
```

---

## Environment Variables

**Required:**
```bash
# Supabase
SUPABASE_URL=https://flisguvsodactmddejqz.supabase.co
SUPABASE_SERVICE_KEY=your-service-key

# Gemini (temporary, will migrate to Vertex AI)
GEMINI_API_KEY=your-gemini-key

# Authentication
DAVE_API_KEY=your-dave-api-key
ADMIN_API_KEY=your-admin-api-key

# Service
SERVICE_NAME=dave
ENVIRONMENT=development
LOG_LEVEL=INFO
```

**Optional:**
```bash
# Rate Limiting
RATE_LIMIT_ENABLED=true
REDIS_URL=redis://localhost:6379
REDIS_PASSWORD=

# Caching
CACHE_TTL_PROMPTS=300

# CORS
CORS_ORIGINS=http://localhost:3000,https://employa.work

# Observability
OTLP_ENDPOINT=http://localhost:4318
```

---

## API Endpoints Summary

### Health
- `GET /` - Basic status
- `GET /health` - Liveness probe
- `GET /health/ready` - Readiness probe (checks dependencies)
- `GET /health/debug/prompts` - Prompt cache health

### Chat (`/api/v1/chat`)
- `POST /message` - Non-streaming chat
- `GET /stream` - SSE streaming chat
- `POST /start` - Start new conversation with welcome
- `GET /conversations` - List user conversations
- `GET /conversations/{id}` - Get conversation detail
- `DELETE /conversations/{id}` - Soft delete conversation

### Knowledge (`/api/v1/knowledge`)
- `POST /search` - Hybrid/semantic/fulltext search
- `GET /articles/{id}` - Get article by ID
- `GET /articles/slug/{slug}` - Get article by slug
- `GET /faqs` - List FAQs (with filters)
- `GET /categories` - List categories
- `GET /recovery` - Recovery-focused articles

### Admin Prompts (`/api/v1/admin/prompts`)
- `GET /` - List prompts (paginated)
- `GET /categories` - List categories with counts
- `GET /{id}` - Get prompt detail
- `PUT /{id}` - Create new version
- `POST /{id}/rollback` - Rollback to version
- `DELETE /cache` - Clear prompt cache

### Nudges (`/api/v1/nudges`)
- `POST /generate` - Generate single nudge
- `POST /batch` - Generate batch of nudges

---

## Testing Resources

**Testing Standards:** `ProjectPhoenix/docs/standards/testing-tdd.md`

**Test Files Location:** `ProjectPhoenix/services/dave/tests/`

**Coverage Reports:**
- Terminal: Run tests with `--cov-report=term-missing`
- HTML: Run with `--cov-report=html`, open `htmlcov/index.html`

**Mocking Patterns:**

```python
# Mock Supabase
@pytest.fixture
def mock_supabase(self):
    mock = MagicMock()
    mock.table.return_value = mock
    mock.select.return_value = mock
    mock.eq.return_value = mock
    mock.execute.return_value = mock
    mock.execute.return_value.data = [{"id": "123"}]
    return mock

# Mock Gemini
@pytest.fixture
def mock_gemini(self):
    mock = MagicMock()
    mock.generate = AsyncMock(return_value="AI response")
    mock.generate_stream = AsyncMock()
    mock.generate_stream.return_value.__aiter__.return_value = iter(["chunk1", "chunk2"])
    return mock

# Mock HTTP Client
with patch('api.app.repositories.knowledge.get_http_client') as mock_get:
    mock_client = MagicMock()
    mock_response = MagicMock()
    mock_response.status_code = 200
    mock_response.text = "<html>content</html>"
    mock_client.get = AsyncMock(return_value=mock_response)
    mock_get.return_value = mock_client
```

---

## Skills Available

When using Claude Code, invoke these skills for specialized help:

- **`testing-engineer`** - Comprehensive test writing (currently active)
- **`backend-developer`** - FastAPI service development
- **`security-engineer`** - HIPAA compliance, RLS policies, mTLS
- **`monitoring-observability-engineer`** - Metrics, tracing, logging
- **`sql-pro`** - Supabase/PostgreSQL optimization
- **`performance-engineer`** - Load testing, optimization
- **`documentation-engineer`** - Runbooks, ADRs, OpenAPI
- **`refactoring-specialist`** - Code cleanup, optimization

---

## Next Steps for Continuation

### Immediate (This Week)
1. âœ… **Create test_services_dave_chat.py** (~8% coverage boost)
2. âœ… **Create test_routes_chat.py** (~5% coverage boost)
3. âœ… **Create test_clients_gemini.py** (~5% coverage boost)
4. âœ… **Reach 85% coverage threshold** (CI/CD gate)

### Short Term (Next Week)
5. **Security Hardening (Phase 2)**
   - Migrate secrets to GCP Secret Manager
   - Implement Supabase RLS policies
   - Add security scanning to CI/CD

6. **Observability (Phase 3)**
   - Add Prometheus metrics endpoint
   - Enhance structured logging
   - Create Cloud Monitoring dashboards

### Medium Term (Next 2 Weeks)
7. **Documentation (Phase 4)**
   - Expand runbook with operational procedures
   - Create 6+ ADRs for key decisions
   - Complete OpenAPI specification

8. **Code Cleanup (Phase 5)**
   - Resolve all TODOs/FIXMEs
   - Add missing type hints
   - Dependency audit

### Long Term (Next Month)
9. **Load Testing (Phase 6)**
   - Create k6 load test scenarios
   - Establish performance baselines
   - Tune Cloud Run autoscaling

10. **Final Validation (Phase 7)**
    - All governance gates passed
    - Production deployment
    - 24-hour monitoring

11. **Vertex AI Migration**
    - Migrate from google-generativeai to google-cloud-aiplatform
    - Enable Grounding with Google Search
    - Vertex AI Prompt Management UI

---

## Success Criteria (From Plan)

### Gate 1: Code Quality âœ… When Complete
- [x] 85%+ test coverage (currently 59%, need 26% more)
- [ ] All linting/type checking passing
- [ ] No Critical/High vulnerabilities

### Gate 2: Documentation
- [ ] Comprehensive runbook (150+ lines)
- [ ] 6+ ADRs for key decisions
- [ ] Complete OpenAPI 3.1.0 spec
- [ ] Enhanced README with architecture

### Gate 3: Compliance
- [ ] HIPAA checklist 100% complete
- [ ] All secrets in GCP Secret Manager
- [ ] RLS policies implemented and tested
- [ ] mTLS configured
- [ ] Threat model documented

### Gate 4: Observability
- [ ] `/metrics` endpoint exposed
- [ ] 3 SLOs with alerting (availability, latency, error rate)
- [ ] Cloud Monitoring dashboards
- [ ] PHI-redacted structured logging
- [ ] OpenTelemetry tracing

### Gate 5: Cleanup
- [ ] All TODOs resolved
- [ ] 100% type hint coverage
- [ ] `.env.example` complete
- [ ] Dependencies audited and pinned

### Production Ready
- [ ] All 5 governance gates passed
- [ ] Load tests passing (100 VUs sustained)
- [ ] SLO targets met (<800ms p95, 99.9% availability)
- [ ] Successful production deployment
- [ ] 24-hour post-deployment monitoring clean

---

## Important Context for Next Agent

### User Expectations
- **Coverage is REQUIRED, not optional** - User emphasized this multiple times
- **REAL coverage over numbers** - "we are not just looking to hit the 85% number, we need REAL coverage"
- **Follow established processes** - User wants adherence to testing standards and TDD workflow
- **Quality over speed** - Take time to write meaningful tests that verify business logic

### Testing Philosophy
- Write tests that verify BEHAVIOR, not just hit coverage numbers
- Test business logic, edge cases, error handling
- Mock external dependencies (Supabase, Gemini, HTTP)
- Use AsyncMock for all async methods
- Follow established patterns from existing test files

### Files to Reference
- **Testing standards**: `ProjectPhoenix/docs/standards/testing-tdd.md`
- **Dave spec**: `ProjectPhoenix/docs/services/dave/spec.md`
- **Full plan**: `C:\Users\damiy\.claude\plans\parsed-swimming-token.md`
- **Testing handoff**: `ProjectPhoenix/services/dave/TESTING_HANDOFF.md`
- **Existing tests**: `ProjectPhoenix/services/dave/tests/` (9 files to learn patterns from)

### Code Patterns to Follow
- All imports: `from api.app.*` (not `from app.*`)
- Pydantic v2: `.model_dump()` (not `.dict()`)
- Async testing: `@pytest.mark.asyncio` + `AsyncMock`
- Test markers: `@pytest.mark.unit` for unit tests
- Fixture structure: See `test_services_prompt_manager.py` for examples

---

## Contact Context

This handoff was prepared during an active testing session focused on achieving the REQUIRED 85% test coverage for Dave service. The work is well-organized with:
- Clear testing patterns established
- 9 comprehensive test files created
- 257 tests passing (5 failing with low impact)
- 59% coverage achieved (26% gap to target)
- All core business logic modules at 80%+ coverage

The next agent should continue with `test_services_dave_chat.py` as the highest-priority task, following the patterns in existing test files.

**All progress is tracked in:**
- This document (complete handoff)
- `TESTING_HANDOFF.md` (testing-specific details)
- `C:\Users\damiy\.claude\plans\parsed-swimming-token.md` (full 7-phase plan)
- GitHub repository: vscoder427/Dave-Chatbot (check for issues/PRs)

---

## GitHub Repository Status

**Repository:** vscoder427/Dave-Chatbot

To check current status:
```bash
"C:\Program Files\GitHub CLI\gh.exe" repo view vscoder427/Dave-Chatbot
"C:\Program Files\GitHub CLI\gh.exe" issue list --repo vscoder427/Dave-Chatbot
"C:\Program Files\GitHub CLI\gh.exe" pr list --repo vscoder427/Dave-Chatbot
```

**Note:** Use full path for `gh` command on Windows (not in PATH).

---

**End of Complete Handoff Document**
